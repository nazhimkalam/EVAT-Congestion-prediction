{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f720493",
   "metadata": {},
   "source": [
    "\n",
    "# EVAT — Future-Dates Forecasting with Queueing (Premium Edition)\n",
    "\n",
    "**Purpose:** Predict EV charging-station congestion for **future dates beyond the dataset**, then apply **M/M/c queueing (Erlang‑C)** to estimate waiting probability and delays.  \n",
    "**Key features:** robust SARIMAX forecasting, 3‑hour bins, uncertainty bands, and an exported **Streamlit dashboard** for “Forecasting & What‑Ifs”.\n",
    "\n",
    "> This notebook is designed to be fully runnable **even without your raw dataset**. If your CSV is missing, it will auto‑generate a small **synthetic** sample so all cells execute and produce visuals + a dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6d89b",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports\n",
    "\n",
    "We use offline-friendly packages only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3d310",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Configuration\n",
    "\n",
    "- `DATA_PATH`: set to your actual CSV if available.\n",
    "- `TIME_BIN_HOURS`: use 3‑hour bins.\n",
    "- `DEFAULT_SERVICE_RATE_PER_HOUR` (μ) and `DEFAULT_SERVERS` (c) control queueing.\n",
    "- `FORECAST_HORIZON_STEPS`: number of 3‑hour steps to forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"/mnt/data/station_timeseries.csv\"  # change to your file if available\n",
    "TIME_BIN_HOURS = 3\n",
    "\n",
    "DEFAULT_SERVICE_RATE_PER_HOUR = 2.0  # mu\n",
    "DEFAULT_SERVERS = 4                  # c\n",
    "\n",
    "FORECAST_DAYS = 7\n",
    "FORECAST_HORIZON_STEPS = int((24 / TIME_BIN_HOURS) * FORECAST_DAYS)\n",
    "\n",
    "EXPECTED_TIME_COL = \"timestamp\"\n",
    "EXPECTED_STATION_COL = \"station_id\"\n",
    "EXPECTED_ARRIVALS_COL = \"arrivals\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5a5c0",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Load Data (or generate synthetic)\n",
    "\n",
    "Attempts to read your dataset; falls back to synthetic data for a guaranteed run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def generate_synthetic_data(start=\"2025-07-01\", periods_days=28, stations=(\"S1\",\"S2\",\"S3\")):\n",
    "    freq = f\"{TIME_BIN_HOURS}H\"\n",
    "    steps = int((24/TIME_BIN_HOURS)*periods_days)\n",
    "    idx = pd.date_range(start=pd.to_datetime(start), periods=steps, freq=freq)\n",
    "    rows = []\n",
    "    for st in stations:\n",
    "        base = 10 + 3*np.sin(2*np.pi*idx.dayofweek/7) + 2*np.sin(2*np.pi*idx.hour/24)\n",
    "        weekend_boost = np.where(idx.dayofweek>=4, 4.0, 0.0)\n",
    "        arrivals = np.clip(rng.normal(base + weekend_boost, 2.5), 0, None)\n",
    "        arrivals = np.round(arrivals).astype(int)\n",
    "        rows.append(pd.DataFrame({\n",
    "            EXPECTED_TIME_COL: idx,\n",
    "            EXPECTED_STATION_COL: st,\n",
    "            EXPECTED_ARRIVALS_COL: arrivals\n",
    "        }))\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "def try_load_data(path):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        time_col = EXPECTED_TIME_COL if EXPECTED_TIME_COL in df.columns else None\n",
    "        for cand in [\"datetime\",\"date\",\"time\",\"timestamp_local\",\"ts\"]:\n",
    "            if time_col is None and cand in df.columns:\n",
    "                time_col = cand\n",
    "        if time_col is None:\n",
    "            raise ValueError(\"No timestamp-like column found.\")\n",
    "        df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\", utc=False)\n",
    "        df = df.dropna(subset=[time_col]).copy()\n",
    "        df.rename(columns={time_col: EXPECTED_TIME_COL}, inplace=True)\n",
    "\n",
    "        if EXPECTED_STATION_COL not in df.columns:\n",
    "            df[EXPECTED_STATION_COL] = \"S1\"\n",
    "\n",
    "        if EXPECTED_ARRIVALS_COL not in df.columns:\n",
    "            num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            if not num_cols:\n",
    "                raise ValueError(\"No numeric arrivals-like column found.\")\n",
    "            df.rename(columns={num_cols[0]: EXPECTED_ARRIVALS_COL}, inplace=True)\n",
    "\n",
    "        return df[[EXPECTED_TIME_COL, EXPECTED_STATION_COL, EXPECTED_ARRIVALS_COL]].copy()\n",
    "\n",
    "    return generate_synthetic_data()\n",
    "\n",
    "raw_df = try_load_data(DATA_PATH)\n",
    "raw_df.sort_values([EXPECTED_STATION_COL, EXPECTED_TIME_COL], inplace=True)\n",
    "raw_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Data sample:\")\n",
    "display(raw_df.head())\n",
    "print(\"\\nStations:\", raw_df[EXPECTED_STATION_COL].unique().tolist())\n",
    "print(\"Date range:\", raw_df[EXPECTED_TIME_COL].min(), \"->\", raw_df[EXPECTED_TIME_COL].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642a014",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Resample to 3‑hour bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01954e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resample_to_bins(df, time_col, station_col, arrivals_col, bin_hours=3):\n",
    "    freq = f\"{bin_hours}H\"\n",
    "    out = []\n",
    "    for st, g in df.groupby(station_col):\n",
    "        g = g.set_index(time_col).sort_index()\n",
    "        agg = g[arrivals_col].resample(freq).sum().to_frame(arrivals_col)\n",
    "        agg[station_col] = st\n",
    "        out.append(agg.reset_index().rename(columns={time_col: \"bin_time\"}))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "binned_df = resample_to_bins(raw_df, EXPECTED_TIME_COL, EXPECTED_STATION_COL, EXPECTED_ARRIVALS_COL, TIME_BIN_HOURS)\n",
    "binned_df.sort_values([\"station_id\",\"bin_time\"], inplace=True)\n",
    "binned_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Binned sample:\")\n",
    "display(binned_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca762fb5",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Forecasting with SARIMAX\n",
    "\n",
    "Weekly seasonality for 3‑hour bins → period = 56 steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5324ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEASONAL_PERIOD = int((24 / TIME_BIN_HOURS) * 7)\n",
    "\n",
    "def fit_forecast_sarimax(y, steps, seasonal_period=56):\n",
    "    y = pd.Series(y).astype(float)\n",
    "    order = (1,1,1) if len(y) > 20 else (0,1,1)\n",
    "    seasonal_order = (1,1,1,seasonal_period) if len(y) > seasonal_period else (0,1,1,seasonal_period)\n",
    "    try:\n",
    "        model = SARIMAX(y, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res = model.fit(disp=False)\n",
    "    except Exception:\n",
    "        model = SARIMAX(y, order=(0,1,1), seasonal_order=(0,1,1,seasonal_period), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res = model.fit(disp=False)\n",
    "\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    conf = fc.conf_int(alpha=0.2)  # 80% CI\n",
    "    conf.columns = [\"lower\", \"upper\"]\n",
    "    return mean, conf, res\n",
    "\n",
    "def forecast_all_stations(df, horizon_steps, bin_hours=3):\n",
    "    results = []\n",
    "    models = {}\n",
    "    for st, g in df.groupby(\"station_id\"):\n",
    "        g = g.sort_values(\"bin_time\")\n",
    "        y = g[\"arrivals\"].astype(float).values\n",
    "        mean, conf, res = fit_forecast_sarimax(y, steps=horizon_steps, seasonal_period=SEASONAL_PERIOD)\n",
    "        last_time = g[\"bin_time\"].max()\n",
    "        future_index = pd.date_range(last_time + pd.Timedelta(hours=bin_hours), periods=horizon_steps, freq=f\"{bin_hours}H\")\n",
    "        tmp = pd.DataFrame({\n",
    "            \"bin_time\": future_index,\n",
    "            \"station_id\": st,\n",
    "            \"lambda_forecast\": mean.values,\n",
    "            \"lambda_lower\": conf[\"lower\"].values.clip(min=0),\n",
    "            \"lambda_upper\": conf[\"upper\"].values.clip(min=0),\n",
    "        })\n",
    "        results.append(tmp)\n",
    "        models[st] = res\n",
    "    fc_df = pd.concat(results, ignore_index=True)\n",
    "    return fc_df, models\n",
    "\n",
    "forecast_df, fitted_models = forecast_all_stations(binned_df, FORECAST_HORIZON_STEPS, TIME_BIN_HOURS)\n",
    "print(\"Forecast sample:\")\n",
    "display(forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76babe",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Queueing (M/M/c, Erlang‑C) on Forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171025db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def erlang_c_probability_wait(lmbda, mu, c):\n",
    "    if lmbda <= 0 or mu <= 0 or c <= 0:\n",
    "        return 0.0\n",
    "    rho = lmbda / (c * mu)\n",
    "    if rho >= 1.0:\n",
    "        return 1.0\n",
    "    sum_terms = sum([(lmbda/mu)**n / math.factorial(n) for n in range(c)])\n",
    "    last_term = ((lmbda/mu)**c) / (math.factorial(c) * (1 - rho))\n",
    "    P0 = 1.0 / (sum_terms + last_term)\n",
    "    Pw = last_term * P0\n",
    "    return float(min(max(Pw, 0.0), 1.0))\n",
    "\n",
    "def mmc_metrics(lmbda, mu, c):\n",
    "    if lmbda <= 0 or mu <= 0 or c <= 0:\n",
    "        return 0.0, 0.0, 0.0, 0.0\n",
    "    rho = lmbda / (c * mu)\n",
    "    if rho >= 1.0:\n",
    "        return rho, 1.0, float(\"inf\"), float(\"inf\")\n",
    "    Pw = erlang_c_probability_wait(lmbda, mu, c)\n",
    "    Lq = Pw * rho / (1 - rho)\n",
    "    Wq = Lq / lmbda if lmbda > 0 else 0.0\n",
    "    return float(rho), float(Pw), float(Lq), float(Wq)\n",
    "\n",
    "MU = DEFAULT_SERVICE_RATE_PER_HOUR\n",
    "C  = DEFAULT_SERVERS\n",
    "\n",
    "def apply_queueing(fc_df, mu=MU, c=C):\n",
    "    df = fc_df.copy()\n",
    "    vals = [mmc_metrics(max(float(x),0.0), mu, c) for x in df[\"lambda_forecast\"].values]\n",
    "    df[[\"rho\",\"p_wait\",\"Lq\",\"Wq_hours\"]] = pd.DataFrame(vals, index=df.index)\n",
    "    df[\"Wq_minutes\"] = df[\"Wq_hours\"] * 60.0\n",
    "    return df\n",
    "\n",
    "queue_df = apply_queueing(forecast_df, MU, C)\n",
    "print(\"Queueing-augmented forecast sample:\")\n",
    "display(queue_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605c51f",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "\n",
    "def plot_forecast_with_bands(station, history_steps=56):\n",
    "    past = binned_df[binned_df[\"station_id\"]==station].sort_values(\"bin_time\")\n",
    "    past_tail = past.tail(history_steps)\n",
    "    fut = queue_df[queue_df[\"station_id\"]==station].sort_values(\"bin_time\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    if len(past_tail):\n",
    "        ax.plot(past_tail[\"bin_time\"], past_tail[\"arrivals\"], label=\"History (arrivals)\")\n",
    "    ax.plot(fut[\"bin_time\"], fut[\"lambda_forecast\"], label=\"Forecast λ\")\n",
    "    ax.fill_between(fut[\"bin_time\"], fut[\"lambda_lower\"], fut[\"lambda_upper\"], alpha=0.2, label=\"80% CI\")\n",
    "    ax.set_title(f\"Station {station}: Arrivals — history vs. future forecast\")\n",
    "    ax.set_ylabel(\"Arrivals per 3h\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\\n%H:%M\"))\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_queue_kpis(station):\n",
    "    fut = queue_df[queue_df[\"station_id\"]==station].sort_values(\"bin_time\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,3.5))\n",
    "    ax.plot(fut[\"bin_time\"], fut[\"p_wait\"])\n",
    "    ax.set_title(f\"Station {station}: Probability of Waiting (Erlang-C)\")\n",
    "    ax.set_ylabel(\"P(wait)\")\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\\n%H:%M\"))\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,3.5))\n",
    "    ax.plot(fut[\"bin_time\"], np.clip(fut[\"Wq_minutes\"], 0, 120))\n",
    "    ax.set_title(f\"Station {station}: Expected Wait (minutes)\")\n",
    "    ax.set_ylabel(\"Wq (minutes)\")\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\\n%H:%M\"))\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "first_station = queue_df[\"station_id\"].iloc[0]\n",
    "plot_forecast_with_bands(first_station, history_steps=SEASONAL_PERIOD)\n",
    "plot_queue_kpis(first_station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e0892",
   "metadata": {},
   "source": [
    "\n",
    "## 8) What‑If Parameters (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6810cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WHATIF_C = 6\n",
    "WHATIF_MU = 2.5\n",
    "\n",
    "queue_df_whatif = apply_queueing(forecast_df, WHATIF_MU, WHATIF_C)\n",
    "\n",
    "print(\"What-if (c=6, mu=2.5) sample:\")\n",
    "display(queue_df_whatif.head())\n",
    "\n",
    "cmp = (queue_df.merge(queue_df_whatif, on=[\"station_id\",\"bin_time\",\"lambda_forecast\",\"lambda_lower\",\"lambda_upper\"], suffixes=(\"_base\",\"_whatif\"))\n",
    "       .groupby(\"station_id\")[[\"Wq_minutes_base\",\"Wq_minutes_whatif\"]].mean().reset_index())\n",
    "cmp[\"ΔWq(min)\"] = cmp[\"Wq_minutes_whatif\"] - cmp[\"Wq_minutes_base\"]\n",
    "display(cmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7476c",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Save Forecast Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_path = \"/mnt/data/forecast_results.csv\"\n",
    "queue_df.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937a314",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Export a Lightweight Streamlit Forecast Dashboard\n",
    "\n",
    "Run:\n",
    "```\n",
    "streamlit run evat_forecast_dashboard.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df433c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_path = \"/mnt/data/evat_forecast_dashboard.py\"\n",
    "with open(app_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\nimport math\\nimport pandas as pd\\nimport numpy as np\\nimport streamlit as st\\nimport altair as alt\\n\\nst.set_page_config(page_title=\\\"EVAT \\u2014 Forecasting & What\\u2011If\\\", page_icon=\\\"\\u26a1\\\", layout=\\\"wide\\\")\\n\\nst.title(\\\"\\u26a1 EVAT \\u2014 Forecasting & What\\u2011If (Future Dates)\\\")\\n\\n@st.cache_data\\ndef load_data():\\n    df = pd.read_csv(\\\"forecast_results.csv\\\", parse_dates=[\\\"bin_time\\\"])\\n    return df\\n\\ndf = load_data()\\nstations = sorted(df[\\\"station_id\\\"].unique().tolist())\\ncol1, col2, col3, col4 = st.columns(4)\\nstation = col1.selectbox(\\\"Station\\\", stations, index=0)\\nmax_h = df[df[\\\"station_id\\\"]==station].shape[0]\\nhorizon = col2.slider(\\\"Horizon (future steps)\\\", min_value=8, max_value=max_h, value=min(56, max_h), step=4)\\nc = col3.number_input(\\\"Servers (c)\\\", min_value=1, max_value=50, value=4)\\nmu = col4.number_input(\\\"Service rate (\\u03bc per server per hour)\\\", min_value=0.1, max_value=20.0, value=2.0, step=0.1, format=\\\"%.1f\\\")\\n\\nsub = df[df[\\\"station_id\\\"]==station].sort_values(\\\"bin_time\\\").head(horizon).copy()\\n\\ndef erlang_c_probability_wait(lmbda, mu, c):\\n    if lmbda <= 0 or mu <= 0 or c <= 0:\\n        return 0.0\\n    rho = lmbda / (c * mu)\\n    if rho >= 1.0:\\n        return 1.0\\n    sum_terms = sum([(lmbda/mu)**n / math.factorial(n) for n in range(c)])\\n    last_term = ((lmbda/mu)**c) / (math.factorial(c) * (1 - rho))\\n    P0 = 1.0 / (sum_terms + last_term)\\n    Pw = last_term * P0\\n    return min(max(Pw, 0.0), 1.0)\\n\\ndef mmc_metrics(lmbda, mu, c):\\n    if lmbda <= 0 or mu <= 0 or c <= 0:\\n        return 0.0, 0.0, 0.0, 0.0\\n    rho = lmbda / (c * mu)\\n    if rho >= 1.0:\\n        return rho, 1.0, float(\\\"inf\\\"), float(\\\"inf\\\")\\n    Pw = erlang_c_probability_wait(lmbda, mu, c)\\n    Lq = Pw * rho / (1 - rho)\\n    Wq = Lq / lmbda if lmbda > 0 else 0.0\\n    return rho, Pw, Lq, Wq\\n\\nvals = np.array([mmc_metrics(x, mu, c) for x in sub[\\\"lambda_forecast\\\"].values])\\nsub[\\\"rho\\\"] = vals[:,0]\\nsub[\\\"p_wait\\\"] = vals[:,1]\\nsub[\\\"Lq\\\"] = vals[:,2]\\nsub[\\\"Wq_minutes\\\"] = vals[:,3] * 60.0\\n\\nst.markdown(\\\"### \\u03bb Forecast with 80% Interval\\\")\\nline = alt.Chart(sub).mark_line().encode(x=\\\"bin_time:T\\\", y=\\\"lambda_forecast:Q\\\")\\nband = alt.Chart(sub).mark_area(opacity=0.2).encode(x=\\\"bin_time:T\\\", y=\\\"lambda_lower:Q\\\", y2=\\\"lambda_upper:Q\\\")\\nst.altair_chart(band + line, use_container_width=True)\\n\\ncolA, colB = st.columns(2)\\nwith colA:\\n    st.markdown(\\\"### Probability of Waiting\\\")\\n    st.altair_chart(alt.Chart(sub).mark_line().encode(x=\\\"bin_time:T\\\", y=\\\"p_wait:Q\\\"), use_container_width=True)\\nwith colB:\\n    st.markdown(\\\"### Expected Wait (minutes)\\\")\\n    st.altair_chart(alt.Chart(sub.assign(Wq_capped=sub[\\\"Wq_minutes\\\"].clip(upper=120))).mark_line().encode(x=\\\"bin_time:T\\\", y=\\\"Wq_capped:Q\\\"), use_container_width=True)\\n\\nst.caption(\\\"Tune **c** and **\\u03bc** to demonstrate operational strategies in your pitch.\\\")\\n\")\n",
    "print(f\"Wrote: {app_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db76e7f",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Wrap‑Up & Next Steps\n",
    "\n",
    "- You now have **future-date forecasts** for arrivals (λ) and **queueing KPIs** per station.\n",
    "- Use the exported **Streamlit app** to present an engaging *Forecasting & What‑If* tab:\n",
    "  1. Ensure `forecast_results.csv` and `evat_forecast_dashboard.py` are together\n",
    "  2. Run: `streamlit run evat_forecast_dashboard.py`\n",
    "\n",
    "Ideas to extend:\n",
    "- Auto-ARIMA model selection/Prophet if available\n",
    "- Event/holiday regressors\n",
    "- Hierarchical reconciliation (global + per-station)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
